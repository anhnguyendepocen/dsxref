---
title: "Getting and Cleaning Data"
output:
  html_document:
    highlight: pygments
    keep_md: yes
---

### How do I read a csv file?

We are using the iris dataset hosted on Github by [Vincent Arel-Bundock](http://vincentarelbundock.github.io/Rdatasets/datasets.html).

R:
```{r readcsv-R, cache=TRUE}
url = "http://vincentarelbundock.github.io/Rdatasets/csv/datasets/iris.csv"
download.file(url, "iris.csv", quiet=TRUE)
iris <- read.csv("iris.csv", header=TRUE, stringsAsFactors=FALSE)
head(iris, 3)
```

Python:
```{r readcsv-python, engine='python', cache=TRUE}
import pandas as pd
import urllib
url = "http://vincentarelbundock.github.io/Rdatasets/csv/datasets/iris.csv"
urllib.urlretrieve(url, "iris.csv")
iris = pd.read_csv("iris.csv", header=0)
print iris.head(n=3)
```

### How do I read an Excel(xlsx) file?

We are using the iris dataset saved in the Excel xlsx format.

R:
```{r readxlsx-R, cache=TRUE}
library(xlsx)
library(httr)
url <- "https://rawgit.com/yoke2/dsxref/master/iris.xlsx"
# note that we are handling HTTPS connection using httr package.
GET(url, write_disk("iris.xlsx", overwrite=TRUE))
iris <- read.xlsx("iris.xlsx", sheetIndex=1, header=TRUE)
head(iris, 3)
```

Python:
```{r readxlsx-python, engine='python', cache=TRUE}
import pandas as pd
import urllib
url = "https://rawgit.com/yoke2/dsxref/master/iris.xlsx"
urllib.urlretrieve(url, "iris.xlsx")
iris = pd.read_excel("iris.xlsx", sheetname=0, header=0)
print iris.head(n=3)
```

### How do I read a json file?

We are using [JSONPlaceHolder](http://jsonplaceholder.typicode.com/) to simulate JSON dataset.

R:
```{r readjson-R, cache=TRUE}
library(jsonlite)
url <- "http://jsonplaceholder.typicode.com/users"
data <- fromJSON(url)
head(data, 3)
```

Python:
```{r readjson-python, engine='python', cache=TRUE}
import pandas as pd
import requests
url = "http://jsonplaceholder.typicode.com/users"
response = requests.get(url)
data = response.json()
df = pd.io.json.json_normalize(data)
print df.head(n=3)
```

### How do I search and retrieve Tweets from Twitter? (via packages)

You will need Twitter developer account set up for consumer key, consumer secret, access token and access secret. We are using twitteR package in R and tweepy package in Python.

R:
```{r readtweets-R}
library(twitteR)
consumerKey <- readLines("twitterkey.txt")
consumerSecret <- readLines("twittersecret.txt")
accessToken <- readLines("twitteraccesstoken.txt")
accessTokenSecret <- readLines("twitteraccesstokensecret.txt")
setup_twitter_oauth(consumerKey,consumerSecret,accessToken,accessTokenSecret)

tweets <- searchTwitter("#datascience", n=5)
tweetsDF <- twListToDF(tweets)
head(tweetsDF,3)
```

Python:
```{r readtweets-python, engine='python'}
import tweepy
import pandas as pd
file1 = open('twitterkey.txt', 'r')
file2 = open('twittersecret.txt', 'r')
file3 = open('twitteraccesstoken.txt', 'r')
file4 = open('twitteraccesstokensecret.txt', 'r')
consumerKey = file1.readline().strip()
consumerSecret = file2.readline().strip()
accessToken = file3.readline().strip()
accessTokenSecret = file4.readline().strip()

auth = tweepy.OAuthHandler(consumerKey, consumerSecret)
auth.set_access_token(accessToken, accessTokenSecret)
api = tweepy.API(auth)
tweets = api.search("datascience",rpp=10)
new = pd.DataFrame()
for tweet in tweets:
    new = new.append(pd.DataFrame.from_dict(tweet.__dict__,orient="index").transpose())
# some columns are in object form that requires more processing
print new.head(n=3)
```

